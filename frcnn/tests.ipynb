{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "Training images per class:\n",
      "{' apple': 10, 'bg': 0}\n",
      "Num classes (including bg) = 2\n",
      "Num train samples 6\n",
      "Num val samples 0\n",
      "loading weights from model_frcnn.hdf5\n",
      "loaded!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model : you are passing a list as input to your model, but the model expects a list of 2 Numpy arrays instead. The list you passed was: [{'imageset': 'trainval', 'bboxes': [{'y2': 769, 'x2': 490, 'x1': 445, 'y1': 732, 'class': ' apple'}], 'filepath': 'apple_images/01_Enrico_Carbognani/conv/P_20170625_184035.jpg', 'width': 720, 'height",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e041f80a1c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mmodel_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training complete, exiting.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \"\"\"\n\u001b[1;32m   1698\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m-> 1699\u001b[0;31m                                     self._feed_input_shapes)\n\u001b[0m\u001b[1;32m   1700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     89\u001b[0m                         \u001b[0;34m' Numpy arrays instead. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0;34m'The list you passed was: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                         str(data)[:200])\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model : you are passing a list as input to your model, but the model expects a list of 2 Numpy arrays instead. The list you passed was: [{'imageset': 'trainval', 'bboxes': [{'y2': 769, 'x2': 490, 'x1': 445, 'y1': 732, 'class': ' apple'}], 'filepath': 'apple_images/01_Enrico_Carbognani/conv/P_20170625_184035.jpg', 'width': 720, 'height"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import config, data_generators\n",
    "from keras_frcnn import losses as losses\n",
    "from keras_frcnn import resnet as nn\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "from keras.utils import generic_utils\n",
    "from keras_frcnn.simple_parser import get_data\n",
    "\n",
    "sys.setrecursionlimit(40000)\n",
    "\n",
    "C = config.Config()\n",
    "\n",
    "\n",
    "all_imgs, classes_count, class_mapping = get_data(\"apple_images/fout_test2.csv\")\n",
    "\n",
    "if 'bg' not in classes_count:\n",
    "\tclasses_count['bg'] = 0\n",
    "\tclass_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "C.class_mapping = class_mapping\n",
    "\n",
    "inv_map = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "print('Training images per class:')\n",
    "pprint.pprint(classes_count)\n",
    "print('Num classes (including bg) = {}'.format(len(classes_count)))\n",
    "\n",
    "with open(\"config.pickle\", 'rb') as f_in:\n",
    "\tC = pickle.load(f_in)\n",
    "\n",
    "C.base_net_weights = \"model_frcnn.hdf5\"\n",
    "    \n",
    "num_imgs = len(all_imgs)\n",
    "\n",
    "train_imgs = [s for s in all_imgs if s['imageset'] == 'trainval']\n",
    "val_imgs = [s for s in all_imgs if s['imageset'] == 'test']\n",
    "\n",
    "print('Num train samples {}'.format(len(train_imgs)))\n",
    "print('Num val samples {}'.format(len(val_imgs)))\n",
    "\n",
    "\n",
    "data_gen_train = data_generators.get_anchor_gt(train_imgs, classes_count, C, K.image_dim_ordering(), mode='train')\n",
    "data_gen_val = data_generators.get_anchor_gt(val_imgs, classes_count, C, K.image_dim_ordering(), mode='val')\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "\tinput_shape_img = (3, None, None)\n",
    "else:\n",
    "\tinput_shape_img = (None, None, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(C.num_rois, 4))\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "# define the RPN, built on the base layers\n",
    "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "rpn = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "classifier = nn.classifier(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count), trainable=True)\n",
    "\n",
    "model_rpn = Model(img_input, rpn[:2])\n",
    "model_classifier = Model([img_input, roi_input], classifier)\n",
    "\n",
    "# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
    "model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n",
    "\n",
    "try:\n",
    "\tprint('loading weights from {}'.format(C.base_net_weights))\n",
    "\tmodel_rpn.load_weights(C.base_net_weights, by_name=True)\n",
    "\tmodel_classifier.load_weights(C.base_net_weights, by_name=True)\n",
    "except e:\n",
    "\tprint(e)\n",
    "finally:\n",
    "    print(\"loaded!\")\n",
    "    \n",
    "optimizer = Adam(lr=1e-4)\n",
    "optimizer_classifier = Adam(lr=1e-4)\n",
    "model_rpn.compile(optimizer=optimizer, loss=[losses.rpn_loss_cls(num_anchors), losses.rpn_loss_regr(num_anchors)])\n",
    "model_classifier.compile(optimizer=optimizer_classifier, loss=[losses.class_loss_cls, losses.class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
    "model_all.compile(optimizer='sgd', loss='mae')\n",
    "\n",
    "predictions=model_all.predict_on_batch(all_imgs)\n",
    "\n",
    "print('Training complete, exiting.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_Enrico_Carbognani\t09_Sofia_Asteria_Piffer  fout.csv\r\n",
      "02_Paolo_Iachemet\t10_Surabhi_Mundana\t fout_test.csv\r\n",
      "03_Sachin_Konan\t\t11.1_Elliot\t\t fout_train.csv\r\n",
      "04_Andrea_Zanin\t\t11.2_Balgeet_Tjinder\t join_csvs.py\r\n",
      "05_Aurnav_Nardelli\t12_Mihir_Patel\t\t jsonsloth_to_csv.py\r\n",
      "06_Gregorio_Giovanazzi\t13_Matteo_Albi\t\t pipeline.sh\r\n",
      "07_Marco_Zamboni\t14_Nunzio_Fallico\t test_imgs\r\n",
      "08_Martina_Parisi\tannotation.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls apple_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([173,  58, 189, 238, 131,   3, 162, 178, 199, 126, 165, 201,  37,\n",
       "        83,  95, 250, 136,  66,  24,  83, 154,  34, 213, 102, 253, 190,\n",
       "        40,  37, 116, 207])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 255, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
